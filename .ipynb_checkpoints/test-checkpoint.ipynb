{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducability\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed(31415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5117 files belonging to 2 classes.\n",
      "Found 5051 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training and validation sets\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    'Kaggle_Computer_Vision/archive/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    'Kaggle_Computer_Vision/archive/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Kaggle_Computer_Vision/savings\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Kaggle_Computer_Vision/savings\\assets\n"
     ]
    }
   ],
   "source": [
    "# Use as pretrained model VGG16\n",
    "pretrained_base = tf.keras.models.load_model(\n",
    "    'Kaggle_Computer_Vision/cv-course-models/vgg16-pretrained-base',\n",
    ")\n",
    "pretrained_base.save(\"Kaggle_Computer_Vision/savings\")  # Use model.save()\n",
    "pretrained_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "80/80 [==============================] - 661s 8s/step - loss: 0.9810 - binary_accuracy: 0.5691 - val_loss: 0.6905 - val_binary_accuracy: 0.5785\n",
      "Epoch 2/30\n",
      "80/80 [==============================] - 461s 6s/step - loss: 0.6891 - binary_accuracy: 0.5787 - val_loss: 0.6879 - val_binary_accuracy: 0.5785\n",
      "Epoch 3/30\n",
      "80/80 [==============================] - 368s 5s/step - loss: 0.6867 - binary_accuracy: 0.5787 - val_loss: 0.6857 - val_binary_accuracy: 0.5785\n",
      "Epoch 4/30\n",
      "80/80 [==============================] - 410s 5s/step - loss: 0.6848 - binary_accuracy: 0.5787 - val_loss: 0.6841 - val_binary_accuracy: 0.5785\n",
      "Epoch 5/30\n",
      "80/80 [==============================] - 400s 5s/step - loss: 0.6834 - binary_accuracy: 0.5787 - val_loss: 0.6829 - val_binary_accuracy: 0.5785\n",
      "Epoch 6/30\n",
      "80/80 [==============================] - 414s 5s/step - loss: 0.6825 - binary_accuracy: 0.5787 - val_loss: 0.6821 - val_binary_accuracy: 0.5785\n",
      "Epoch 7/30\n",
      "80/80 [==============================] - 401s 5s/step - loss: 0.6818 - binary_accuracy: 0.5787 - val_loss: 0.6816 - val_binary_accuracy: 0.5785\n",
      "Epoch 8/30\n",
      "80/80 [==============================] - 397s 5s/step - loss: 0.6814 - binary_accuracy: 0.5787 - val_loss: 0.6813 - val_binary_accuracy: 0.5785\n",
      "Epoch 9/30\n",
      "80/80 [==============================] - 377s 5s/step - loss: 0.6811 - binary_accuracy: 0.5787 - val_loss: 0.6811 - val_binary_accuracy: 0.5785\n",
      "Epoch 10/30\n",
      "80/80 [==============================] - 388s 5s/step - loss: 0.6810 - binary_accuracy: 0.5787 - val_loss: 0.6809 - val_binary_accuracy: 0.5785\n",
      "Epoch 11/30\n",
      "80/80 [==============================] - 376s 5s/step - loss: 0.6809 - binary_accuracy: 0.5787 - val_loss: 0.6809 - val_binary_accuracy: 0.5785\n",
      "Epoch 12/30\n",
      "80/80 [==============================] - 389s 5s/step - loss: 0.6808 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 13/30\n",
      "80/80 [==============================] - 374s 5s/step - loss: 0.6808 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 14/30\n",
      "80/80 [==============================] - 386s 5s/step - loss: 0.6808 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 15/30\n",
      "80/80 [==============================] - 371s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 16/30\n",
      "80/80 [==============================] - 378s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 17/30\n",
      "80/80 [==============================] - 380s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 18/30\n",
      "80/80 [==============================] - 369s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 19/30\n",
      "80/80 [==============================] - 366s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 20/30\n",
      "80/80 [==============================] - 377s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 21/30\n",
      "80/80 [==============================] - 362s 5s/step - loss: 0.6808 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 22/30\n",
      "80/80 [==============================] - 370s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 23/30\n",
      "80/80 [==============================] - 367s 5s/step - loss: 0.6808 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 24/30\n",
      "80/80 [==============================] - 387s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 25/30\n",
      "80/80 [==============================] - 417s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 26/30\n",
      "80/80 [==============================] - 402s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 27/30\n",
      "80/80 [==============================] - 410s 5s/step - loss: 0.6808 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 28/30\n",
      "80/80 [==============================] - 395s 5s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 29/30\n",
      "80/80 [==============================] - 488s 6s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n",
      "Epoch 30/30\n",
      "80/80 [==============================] - 757s 10s/step - loss: 0.6807 - binary_accuracy: 0.5787 - val_loss: 0.6808 - val_binary_accuracy: 0.5785\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train_,\n",
    "    validation_data=ds_valid_,\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m history_frame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m      4\u001b[0m history_frame\u001b[38;5;241m.\u001b[39mloc[:, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mplot()\n\u001b[0;32m      5\u001b[0m history_frame\u001b[38;5;241m.\u001b[39mloc[:, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_binary_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow environment",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
